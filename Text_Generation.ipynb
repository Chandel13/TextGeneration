{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_Generation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnN4IVvpqQBL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import string\n",
        "import requests"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5N2fRRbq2g-",
        "colab_type": "text"
      },
      "source": [
        "#we are using tensorflow and keras and lstm\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUoTO2MmqvY_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "response=requests.get('https://ocw.mit.edu/ans7870/6/6.006/s08/lecturenotes/files/t8.shakespeare.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ap64NfJUqahB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "response.text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDCu5Qu3uQtO",
        "colab_type": "text"
      },
      "source": [
        "####1 )   here  we split whole data  with new line char"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFoIIgDU6xbb",
        "colab_type": "text"
      },
      "source": [
        "#CLEANING DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqOeqMeJtPiU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data=response.text.split('\\n')\n",
        "data[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYnJEcswuDH7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data[253]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EA09i0ZvxmWq",
        "colab_type": "text"
      },
      "source": [
        "####2))  we update the data to remove the header from data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhceIJqpuKuD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data =data[253:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_4JNQZDxirR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9me71dMnGfIr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6WLyZVaySUC",
        "colab_type": "text"
      },
      "source": [
        "####3)   to make data in continuous manner before this it was in line form\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CI0aIuNEx3EA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data=\" \".join(data)\n",
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQtYZOxe7BRq",
        "colab_type": "text"
      },
      "source": [
        "#### 4) removing punctuation and special char and making whole data in lower"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Wvg6QtfyG-U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_text(doc):\n",
        "  tokens=doc.split()\n",
        "  #remove punctuation\n",
        "  table=str.maketrans(' '  , ' ', string.punctuation)\n",
        "  tokens=[w.translate(table) for w in tokens ]\n",
        "  #remove that are not alpha numeric or special chracter\n",
        "  tokens=[word for word in tokens if word.isalpha()]\n",
        "  #convert into lower letter case \n",
        "  tokens=[word.lower() for word in tokens]\n",
        "  return tokens\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJ-_rD5X1acy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokens=clean_text(data)\n",
        "print(tokens[:50])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-OzHRXc1rY9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93E_k88m5QE6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(set(tokens))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcDJUnSs5TBg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#first 50 is for the input and 1 is for the output\n",
        "length=50+1\n",
        "#list of all senteces made from tokens joining 51 words each\n",
        "lines=[]\n",
        "for i in range(length,len(tokens)):\n",
        "  seq=tokens[i-length:i]\n",
        "  line=' '.join(seq)\n",
        "  lines.append(line)\n",
        "  if i > 200000:\n",
        "    break\n",
        "\n",
        "print(len(lines))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aS0TvFsx59MS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lines[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sm8xZvjK6Em-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokens[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-Mzn4aq6Vm5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#0 to 50 is 51 words\n",
        "tokens[50]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sf2wdbqf6r4G",
        "colab_type": "text"
      },
      "source": [
        "#LSTM MODEL BUILDING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lItBvZto63AL",
        "colab_type": "text"
      },
      "source": [
        "####1)  Preparing x and y"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTuG2Ea7615j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,LSTM,Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jjlzj3fU7YPX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#word embedding giving number to each word converting into integer\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(lines)\n",
        "sequences=tokenizer.texts_to_sequences(lines)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_FDSg5IwCp2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequences=np.array(sequences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTZMAlh3EAhv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequences.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmSiRUIrwMEq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x,y=sequences[:, :-1],sequences[:,-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xoz7CL3aw0es",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WbhTCLbw5X5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y[0] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjEIv2txxevd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tokenizer.word_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1eDi9A8xm3D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size=len(tokenizer.word_index)+1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWViGGGQD9iZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rr0ZZy2mw_5D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y=to_categorical(y,num_classes=vocab_size)\n",
        "x.shape[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luTRIbfsxSgr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seq_length=x.shape[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acdwLDmtzW0D",
        "colab_type": "text"
      },
      "source": [
        "#LSTM model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SKugVa9yMJC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=Sequential()\n",
        "model.add(Embedding( vocab_size, 50, input_length = seq_length))\n",
        "model.add(LSTM(100,return_sequences=True))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(vocab_size,activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKYvDTeEzjGm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuUw3uCu0XCt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile( loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'] )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WHPO7sxy7RL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(x,y,batch_size = 256, epochs=200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujn_cazXDEuC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bKH1XTSCT9O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('/saved_model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YrggfjZCxAf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1 = keras.models.load_model('/saved_model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZcnXWPnD281",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1.fit(x,y,batch_size = 256,epochs= 50 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJPCst8YZJIX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1.save( '/saved_model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QjjMMp1DBJF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_text_seq( model, tokenizer, text_seq_length, seed_text, n_words) :\n",
        "    text = []\n",
        "\n",
        "    for _ in range( n_words ):\n",
        "        encoded = tokenizer.texts_to_sequences ( [seed_text] ) [ 0]\n",
        "        encoded = pad_sequences( [encoded], maxlen = text_seq_length, truncating = 'pre')\n",
        "\n",
        "        y_predict = np.argmax( model.predict_classes( encoded ))\n",
        "\n",
        "        predicted_word = '  '\n",
        "        for word, index in tokenizer.word_index.items() :\n",
        "            if index == y_predict : \n",
        "                predicted_word = word\n",
        "                break\n",
        "            seed_text = seed_text + '  ' + predicted_word\n",
        "            text.append( predicted_word)\n",
        "            \n",
        "    #print(text)\n",
        "    return '   '.join( text ) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nutY78hqx-3S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed_text = lines[1210]\n",
        "seed_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UhOyj_Em1U4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generate_text_seq( model1, tokenizer,  seq_length, seed_text , 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MX57C31VYu19",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}